{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vasu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPTNeoForCausalLM, GPT2Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "config.json: 100%|██████████| 1.35k/1.35k [00:00<00:00, 431kB/s]\n",
      "model.safetensors: 100%|██████████| 5.31G/5.31G [16:12<00:00, 5.46MB/s]\n",
      "tokenizer_config.json: 100%|██████████| 200/200 [00:00<00:00, 104kB/s]\n",
      "vocab.json: 100%|██████████| 798k/798k [00:00<00:00, 3.40MB/s]\n",
      "merges.txt: 100%|██████████| 456k/456k [00:00<00:00, 5.51MB/s]\n",
      "special_tokens_map.json: 100%|██████████| 90.0/90.0 [00:00<00:00, 290kB/s]\n"
     ]
    }
   ],
   "source": [
    "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define the directory path where you want to save the model\n",
    "# output_dir = \"/Users/vasu/Desktop/NLP/gptneo/\"\n",
    "\n",
    "# # Save the tokenizer and model to the specified directory\n",
    "# tokenizer.save_pretrained(output_dir)\n",
    "# model.save_pretrained(output_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    }
   ],
   "source": [
    "input_text = (\n",
    "    \"Breast cancer is\"\n",
    ")\n",
    "\n",
    "input_ids = tokenizer(input_text, return_tensors=\"pt\").input_ids\n",
    "\n",
    "gen_tokens = model.generate(\n",
    "    input_ids,\n",
    "    do_sample=True,\n",
    "    temperature=0.9,\n",
    "    max_length=100,\n",
    ")\n",
    "gen_text = tokenizer.batch_decode(gen_tokens)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast cancer is the second most common cancer among Indian women, with an incidence rate of nearly 18 cases per 100,000. India ranks second among the 12 countries in the world with the highest burden of breast cancer among females ([@bib29]), with a prevalence rate of 18 per 100,000 women ([@bib16], [@bib31]).\n",
      "\n",
      "In India, *in situ* breast cancer (ISBC) accounts for about 18% of all breast cancers, with\n"
     ]
    }
   ],
   "source": [
    "print(gen_text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

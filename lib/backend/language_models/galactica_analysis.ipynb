{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:22:35.932076Z",
     "start_time": "2024-11-26T00:22:32.215609Z"
    }
   },
   "source": [
    "from transformers import AutoTokenizer, OPTForCausalLM\n",
    "import coremltools as ct\n",
    "import torch\n",
    "\n",
    "device = torch.device('cpu')"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Torch version 2.5.0.dev20240809 has not been tested with coremltools. You may run into unexpected errors. Torch 2.4.0 is the most recent version that has been tested.\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download and save the tokenizer"
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:22:41.958012Z",
     "start_time": "2024-11-26T00:22:37.264844Z"
    }
   },
   "source": [
    "model_name = \"facebook/galactica-1.3b\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"facebook/galactica-1.3b\", return_tensors=\"pt\")\n",
    "# Downloading the tokenizer\n",
    "tokenizer.save_pretrained(f\"cache/tokenizer/{model_name}\")\n",
    "\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('cache/tokenizer/facebook/galactica-1.3b/tokenizer_config.json',\n",
       " 'cache/tokenizer/facebook/galactica-1.3b/special_tokens_map.json',\n",
       " 'cache/tokenizer/facebook/galactica-1.3b/tokenizer.json')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Sample input to trace the model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:22:42.024632Z",
     "start_time": "2024-11-26T00:22:42.022503Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_text = \"Breast Cancer is\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "input_ids = inputs[\"input_ids\"].to(device)"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Download and save the model"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:10:00.768929Z",
     "start_time": "2024-11-26T01:09:08.527818Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = OPTForCausalLM.from_pretrained(\"facebook/galactica-1.3b\", device_map=\"mps\", torchscript=True)\n",
    "# save the model\n",
    "model.to(device)\n",
    "model.eval()\n",
    "model.config.return_dict=True\n",
    "model.save_pretrained(f\"cache/model/{model_name}\")"
   ],
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:10:54.309399Z",
     "start_time": "2024-11-26T01:10:44.249614Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Trace the model\n",
    "with torch.no_grad():\n",
    "    traced_model = torch.jit.trace(model, input_ids)\n",
    "\n",
    "# different way to convert the model\n",
    "\n",
    "# Prepare example input\n",
    "# input_ids = torch.randint(0, model.config.vocab_size, (1, 512))\n",
    "\n",
    "# Export the model to ONNX\n",
    "# torch.onnx.export(\n",
    "#     model,\n",
    "#     (input_ids,),\n",
    "#     \"model.onnx\",\n",
    "#     input_names=['input_ids'],\n",
    "#     output_names=['output'],\n",
    "#     dynamic_axes={'input_ids': {0: 'batch_size', 1: 'sequence_length'}},\n",
    "#     opset_version=11,\n",
    "# )\n",
    "\n",
    "# torch.export.export()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:114: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if (input_shape[-1] > 1 or self.sliding_window is not None) and self.is_causal:\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/transformers/modeling_attn_mask_utils.py:162: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if past_key_values_length > 0:\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:193: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_weights.size() != (bsz * self.num_heads, tgt_len, src_len):\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:200: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attention_mask.size() != (bsz, 1, tgt_len, src_len):\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:206: TracerWarning: torch.tensor results are registered as constants in the trace. You can safely ignore this warning if you use this function to create tensors out of constant variables that would be the same every time you call this function. In any other case, this might cause the trace to be incorrect.\n",
      "  attn_weights, torch.tensor(torch.finfo(attn_weights.dtype).min, device=attn_weights.device)\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/transformers/models/opt/modeling_opt.py:239: TracerWarning: Converting a tensor to a Python boolean might cause the trace to be incorrect. We can't record the data flow of Python values, so this value will be treated as a constant in the future. This means that the trace might not generalize to other inputs!\n",
      "  if attn_output.size() != (bsz * self.num_heads, tgt_len, self.head_dim):\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Convert the model"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "mlmodel = ct.convert(\n",
    "    traced_model,\n",
    "    inputs=[ct.TensorType(shape=input_ids.shape, dtype=input_ids.dtype)],\n",
    "    compute_units=ct.ComputeUnit.CPU_ONLY  # or .CPU_AND_NE if you have a device with Neural Engine\n",
    ")"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### Quantization"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:12:13.590655Z",
     "start_time": "2024-11-26T01:11:15.185345Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mlmodel_fp16 = ct.convert(\n",
    "    traced_model,\n",
    "    # model,\n",
    "    # \"model.onnx\",\n",
    "    source=\"auto\",\n",
    "    inputs=[ct.TensorType(shape=input_ids.shape)],\n",
    "    compute_precision=ct.precision.FLOAT16,\n",
    "    convert_to=\"mlprogram\",  # Use ML Program format for advanced features\n",
    ")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops:   0%|          | 0/1967 [00:00<?, ? ops/s]huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Core ML embedding (gather) layer does not support any inputs besides the weights and indices. Those given will be ignored.\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  99%|█████████▊| 1940/1967 [00:00<00:00, 8524.26 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 60.89 passes/s]\n",
      "Running MIL default pipeline:   7%|▋         | 6/89 [00:00<00:01, 57.68 passes/s]/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '169', of the source model, has been renamed to 'var_169' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '176', of the source model, has been renamed to 'var_176' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '275', of the source model, has been renamed to 'var_275' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '282', of the source model, has been renamed to 'var_282' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '381', of the source model, has been renamed to 'var_381' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '388', of the source model, has been renamed to 'var_388' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '487', of the source model, has been renamed to 'var_487' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '494', of the source model, has been renamed to 'var_494' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '593', of the source model, has been renamed to 'var_593' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '600', of the source model, has been renamed to 'var_600' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '699', of the source model, has been renamed to 'var_699' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '706', of the source model, has been renamed to 'var_706' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '805', of the source model, has been renamed to 'var_805' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '812', of the source model, has been renamed to 'var_812' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '911', of the source model, has been renamed to 'var_911' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '918', of the source model, has been renamed to 'var_918' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1017', of the source model, has been renamed to 'var_1017' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1024', of the source model, has been renamed to 'var_1024' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1123', of the source model, has been renamed to 'var_1123' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1130', of the source model, has been renamed to 'var_1130' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1229', of the source model, has been renamed to 'var_1229' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1236', of the source model, has been renamed to 'var_1236' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1335', of the source model, has been renamed to 'var_1335' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1342', of the source model, has been renamed to 'var_1342' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1441', of the source model, has been renamed to 'var_1441' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1448', of the source model, has been renamed to 'var_1448' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1547', of the source model, has been renamed to 'var_1547' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1554', of the source model, has been renamed to 'var_1554' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1653', of the source model, has been renamed to 'var_1653' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1660', of the source model, has been renamed to 'var_1660' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1759', of the source model, has been renamed to 'var_1759' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1766', of the source model, has been renamed to 'var_1766' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1865', of the source model, has been renamed to 'var_1865' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1872', of the source model, has been renamed to 'var_1872' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1971', of the source model, has been renamed to 'var_1971' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '1978', of the source model, has been renamed to 'var_1978' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2077', of the source model, has been renamed to 'var_2077' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2084', of the source model, has been renamed to 'var_2084' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2183', of the source model, has been renamed to 'var_2183' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2190', of the source model, has been renamed to 'var_2190' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2289', of the source model, has been renamed to 'var_2289' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2296', of the source model, has been renamed to 'var_2296' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2395', of the source model, has been renamed to 'var_2395' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2402', of the source model, has been renamed to 'var_2402' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2501', of the source model, has been renamed to 'var_2501' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2508', of the source model, has been renamed to 'var_2508' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2607', of the source model, has been renamed to 'var_2607' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "/Users/rahul/miniconda3/envs/appdevml/lib/python3.10/site-packages/coremltools/converters/mil/mil/passes/defs/preprocess.py:273: UserWarning: Output, '2614', of the source model, has been renamed to 'var_2614' in the Core ML model.\n",
      "  warnings.warn(msg.format(var.name, new_name))\n",
      "Running MIL default pipeline: 100%|██████████| 89/89 [00:25<00:00,  3.48 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:00<00:00, 82.12 passes/s]\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Although I can  8 bit quantization It will take significant time and consideration for every layer"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# Quantization configuration\n",
    "# from coremltools.converters.mil.mil.passes.quantization_passes import OpSelector\n",
    "#\n",
    "# config = ct.QuantizationConfig(\n",
    "#     conversion_type=ct.conversion_type.DYNAMIC,\n",
    "#     op_selector=OpSelector(supported_ops=[\"linear\"]),  # Quantize supported layers\n",
    "# )\n",
    "#\n",
    "# mlmodel_int8 = ct.convert(\n",
    "#     traced_model,\n",
    "#     inputs=[ct.TensorType(shape=input_ids.shape)],\n",
    "#     convert_to=\"mlprogram\",\n",
    "#     quantization_config=config,\n",
    "# )"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:13:43.593999Z",
     "start_time": "2024-11-26T01:13:42.043885Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Save the Quantized model:\n",
    "mlmodel_fp16.save(\"cache/model/quantized/Galactica_1_3B_fp16.mlpackage\")"
   ],
   "outputs": [],
   "execution_count": 23
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Pruning\n",
    "Reducing the model size with pruning even more"
   ]
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:14:09.257998Z",
     "start_time": "2024-11-26T01:14:00.185687Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "# Define pruning amount (e.g., 30%)\n",
    "prune_amount = 0.3\n",
    "\n",
    "# Prune weights in linear layers\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        prune.ln_structured(module, name='weight', amount=prune_amount, n=2, dim=0)"
   ],
   "outputs": [],
   "execution_count": 24
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:14:13.654220Z",
     "start_time": "2024-11-26T01:14:12.428640Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# remove pruning re-parameterization\n",
    "for name, module in model.named_modules():\n",
    "    if isinstance(module, torch.nn.Linear):\n",
    "        prune.remove(module, 'weight')"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:14:25.971494Z",
     "start_time": "2024-11-26T01:14:16.257379Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Re-retrracing the model\n",
    "with torch.no_grad():\n",
    "    traced_model_pruned = torch.jit.trace(model, input_ids)"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T01:15:43.862797Z",
     "start_time": "2024-11-26T01:14:33.351190Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert again to coreml with quantization:\n",
    "mlmodel_pruned_fp16 = ct.convert(\n",
    "    traced_model_pruned,\n",
    "    inputs=[ct.TensorType(shape=input_ids.shape)],\n",
    "    compute_precision=ct.precision.FLOAT16,\n",
    "    convert_to=\"mlprogram\",\n",
    ")\n",
    "mlmodel_pruned_fp16.save(\"cache/model/pruned/Galactica_1_3B_pruned_fp16.mlpackage\")"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Tuple detected at graph output. This will be flattened in the converted model.\n",
      "Converting PyTorch Frontend ==> MIL Ops:   0%|          | 0/1967 [00:00<?, ? ops/s]Core ML embedding (gather) layer does not support any inputs besides the weights and indices. Those given will be ignored.\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Saving value type of int64 into a builtin type of int32, might lose precision!\n",
      "Converting PyTorch Frontend ==> MIL Ops:  99%|█████████▊| 1940/1967 [00:00<00:00, 8374.85 ops/s]\n",
      "Running MIL frontend_pytorch pipeline: 100%|██████████| 5/5 [00:00<00:00, 69.88 passes/s]\n",
      "Running MIL default pipeline: 100%|██████████| 89/89 [00:26<00:00,  3.38 passes/s]\n",
      "Running MIL backend_mlprogram pipeline: 100%|██████████| 12/12 [00:02<00:00,  5.95 passes/s]\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:14:15.578129Z",
     "start_time": "2024-11-25T23:52:19.741868Z"
    }
   },
   "source": [
    "# Set device to CPU\n",
    "device = \"mps\"\n",
    "\n",
    "# Generate text on CPU\n",
    "input_text = \"Breast Cancer is\"\n",
    "# Tokenize input text and get attention mask\n",
    "tokenizer_output = tokenizer(\n",
    "    input_text,\n",
    "    return_tensors=\"pt\",\n",
    "    return_attention_mask=True  # This is True by default but being explicit helps\n",
    ")\n",
    "input_ids = tokenizer_output[\"input_ids\"].to(device)\n",
    "attention_mask = tokenizer_output[\"attention_mask\"].to(device)\n",
    "\n",
    "\n",
    "# Control the maximum number of tokens in the generated text\n",
    "\n",
    "# Generate text\n",
    "outputs = model.generate(\n",
    "    input_ids=input_ids,\n",
    "    attention_mask=attention_mask,\n",
    "    max_length=100\n",
    ")\n",
    "\n",
    "# Decode generated output\n",
    "generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "print(generated_text)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Breast Cancer is the most common cancer in women worldwide. The incidence of breast cancer is increasing in developing countries. The aim of this study was to evaluate the effect of the combination of tamoxifen and raloxifene on the expression of estrogen receptor (ER), progesterone receptor (PR), and human epidermal growth factor receptor 2 (HER2) in breast cancer.\n",
      "\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-26T00:14:15.578388Z",
     "start_time": "2024-11-25T23:00:33.400748Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

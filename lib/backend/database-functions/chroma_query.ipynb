{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb import EmbeddingFunction\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Terminal command to start a local host server\n",
    "## chroma run --path \"G:/All Flutter Applications/NLP with transformers project/chatbot_ic/lib/backend/data/chroma_data\"\n",
    "\n",
    "## instantiate chroma client\n",
    "chroma_internet_client = chromadb.HttpClient(host='16.171.68.145', port=8000, settings=Settings(allow_reset=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create multiple collections\n",
    "persistence_database_path_windows = \"G:/All Flutter Applications/NLP with transformers project/chatbot_ic/lib/backend/data/chroma_data\"\n",
    "\n",
    "persistence_database_path_mac = \"/Users/vasu/Desktop/NLP /project/chatbot_ic_NLP/lib/backend/data/chroma_data\"\n",
    "\n",
    "persistence_database_path_ubuntu = \"/home/ubuntu/chromadb\"\n",
    "\n",
    "## for local persistent database\n",
    "# chroma_internet_client = chromadb.PersistentClient(path=persistence_database_path_mac, settings=Settings(allow_reset=True))\n",
    "\n",
    "\n",
    "def create_chroma_collections(years):\n",
    "    \n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-MiniLM-L6-cos-v1\", normalize_embeddings=True)\n",
    "    \n",
    "    for year in years:\n",
    "        # Specify the path to your JSON file\n",
    "        #json_file_path = f\"G:/All Flutter Applications/NLP with transformers project/chatbot_ic/lib/backend/data/data_json/{year}pubmed.json\"\n",
    "        json_file_path =f\"/Users/vasu/Desktop/NLP /project/chatbot_ic_NLP/lib/backend/data/data_json/{year}pubmed.json\"\n",
    "        # Open the JSON file and load the data\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            dataset = json.load(json_file)\n",
    "            \n",
    "        collection = chroma_internet_client.create_collection(f\"{year}pubmed\", embedding_function=sentence_transformer_ef, metadata={\"hnsw:space\": \"cosine\"})\n",
    "        \n",
    "        collection.add(\n",
    "            ids=[str(entry['PMID']) for entry in dataset],\n",
    "            documents= [ entry['PMID'] + \"<SEP>\" +  entry['Author']+ \"<SEP>\" + entry['Title'] + \"<SEP>\" + entry['Abstract'] for entry in dataset],\n",
    "            metadatas=[\n",
    "                {'author': entry['Author']} for entry in dataset\n",
    "            ],\n",
    "        )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_internet_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/vasu/.pyenv/versions/3.10.0/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "years = ['2013']#, '2014', '2015', '2016-2017', '2018', '2019', '2020-1', '2020-2']  \n",
    "\n",
    "create_chroma_collections(years=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## access 2013 collection\n",
    "collection_2013 = chroma_internet_client.get_collection('2013pubmed')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code for getting top 5 articles based on the similarity index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "# sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-MiniLM-L6-cos-v1\", normalize_embeddings=True)\n",
    "\n",
    "# # User's question\n",
    "# user_question = 'CASK Disorder'\n",
    "\n",
    "# # Embed the user's question\n",
    "# user_question_embedding = sentence_transformer_ef([user_question])[0]\n",
    "\n",
    "# search_results = collection_2013.query(query_embeddings=[user_question_embedding], n_results=5)\n",
    "# print(user_question)\n",
    "# # Print the search results\n",
    "# for i, result in enumerate(search_results['ids'][0]):\n",
    "#     document_id = result\n",
    "#     metadata = search_results['metadatas'][0][i]  # Access the corresponding metadata\n",
    "#     similarity_score = search_results['distances'][0][i]  # Access the corresponding similarity score\n",
    "#     document = search_results['documents'][0][i]  # Access the corresponding document\n",
    "\n",
    "#     print(f\"PMID: {document_id}\")\n",
    "#     # print(f\"Title: {metadata['title']}\")\n",
    "#     print(f\"Author: {metadata['author']}\")\n",
    "#     print(document)\n",
    "#     print(f\"Similarity Score: {similarity_score}\")\n",
    "#     print(\"---------------\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### code for retrieving top article based on the similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Question:\n",
      "CASK Disorder\n",
      "\n",
      "Context with Maximum Similarity Score:\n",
      "24591081<SEP>Avinash M Veerappa<SEP>Genome-wide copy number scan identifies disruption of PCDH11X in developmental dyslexia<SEP>Developmental dyslexia (DD) is a complex heritable disorder with unexpected difficulty in learning to read and spell despite adequate intelligence, education, environment, and normal senses. We performed a whole genome copy number variations (CNV) scan on 11 dyslexic families consisting of 14 dyslexic subjects and 24 non dyslexic members using 1.8 million combined SNP and CNV markers. We found CNVs affecting protocadherin genes in six dyslexics from three families, while none among the non-dyslexic control members showed any CNV in protocadherins. We identified duplications in five cases and a deletion in one case in Xq21.3 region bearing PCDH11X. Unequal recombination between the X-transposed region (XTR) of Yp11.2 and the X chromosome might be causing these structural changes. PCDH11X, expressed in brain is implicated in cell-cell communication, verbal ability, cerebral asymmetry, and dendritic synaptic plasticity, may be regarded as a new candidate gene for dyslexia.\n",
      "Similarity Score: 0.6445419192314148\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-MiniLM-L6-cos-v1\", normalize_embeddings=True)\n",
    "\n",
    "# User's question\n",
    "user_question = 'CASK Disorder'\n",
    "\n",
    "# Embed the user's question\n",
    "user_question_embedding = sentence_transformer_ef([user_question])[0]\n",
    "\n",
    "search_results = collection_2013.query(query_embeddings=[user_question_embedding], n_results=5)\n",
    "\n",
    "# Find the index of the context with the maximum similarity score\n",
    "max_similarity_index = search_results['distances'][0].index(max(search_results['distances'][0]))\n",
    "\n",
    "# Get the context with the maximum similarity score\n",
    "context_with_max_similarity = search_results['documents'][0][max_similarity_index]\n",
    "\n",
    "print(\"User Question:\")\n",
    "print(user_question)\n",
    "print(\"\\nContext with Maximum Similarity Score:\")\n",
    "print(context_with_max_similarity)\n",
    "print(\"Similarity Score:\", max(search_results['distances'][0]))\n",
    "\n",
    "# Now you can feed the user question and the context with maximum similarity score into the Turbo model\n",
    "def get_context_with_max_similarity(user_question):\n",
    "    # Initialize SentenceTransformer model\n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-MiniLM-L6-cos-v1\", normalize_embeddings=True)\n",
    "\n",
    "    # Embed the user's question\n",
    "    user_question_embedding = sentence_transformer_ef([user_question])[0]\n",
    "\n",
    "    # Perform the query using Chroma\n",
    "    search_results = collection_2013.query(query_embeddings=[user_question_embedding], n_results=5)\n",
    "\n",
    "    # Find the index of the context with the maximum similarity score\n",
    "    max_similarity_index = search_results['distances'][0].index(max(search_results['distances'][0]))\n",
    "\n",
    "    # Get the context with the maximum similarity score\n",
    "    context_with_max_similarity = search_results['documents'][0][max_similarity_index]\n",
    "\n",
    "    return context_with_max_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Collection(name=2013pubmed)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chroma_internet_client.list_collections()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

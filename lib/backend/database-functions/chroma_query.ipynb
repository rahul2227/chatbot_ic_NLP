{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb import EmbeddingFunction\n",
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Terminal command to start a local host server\n",
    "## chroma run --path \"G:/All Flutter Applications/NLP with transformers project/chatbot_ic/lib/backend/data/chroma_data\"\n",
    "\n",
    "## instantiate chroma client\n",
    "# chroma_client = chromadb.HttpClient(host=\"localhost\", port=8000)\n",
    "\n",
    "chroma_internet_client = chromadb.HttpClient(host='16.171.68.145', port=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to create multiple collections\n",
    "persistence_database_path_windows = \"G:/All Flutter Applications/NLP with transformers project/chatbot_ic/lib/backend/data/chroma_data\"\n",
    "\n",
    "persistence_database_path_mac = \"/Users/vasu/Desktop/NLP /project/chatbot_ic_NLP/lib/backend/data/chroma_data\"\n",
    "\n",
    "persistence_database_path_ubuntu = \"/home/ubuntu/chromadb\"\n",
    "\n",
    "chroma_internet_client = chromadb.PersistentClient(path=persistence_database_path_ubuntu, settings=Settings(allow_reset=True))\n",
    "\n",
    "def create_chroma_collections(years):\n",
    "    \n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-MiniLM-L6-cos-v1\", normalize_embeddings=True)\n",
    "    \n",
    "    for year in years:\n",
    "        # Specify the path to your JSON file\n",
    "        json_file_path = f\"G:/All Flutter Applications/NLP with transformers project/chatbot_ic/lib/backend/data/data_json/{year}pubmed.json\"\n",
    "\n",
    "        # Open the JSON file and load the data\n",
    "        with open(json_file_path, 'r') as json_file:\n",
    "            dataset = json.load(json_file)\n",
    "            \n",
    "        collection = chroma_internet_client.create_collection(f\"{year}pubmed\", embedding_function=sentence_transformer_ef, metadata={\"hnsw:space\": \"cosine\"})\n",
    "        \n",
    "        collection.add(\n",
    "            ids=[str(entry['PMID']) for entry in dataset],\n",
    "            documents= [ entry['PMID'] + \"<SEP>\" +  entry['Author']+ \"<SEP>\" + entry['Title'] + \"<SEP>\" + entry['Abstract'] for entry in dataset],\n",
    "            metadatas=[\n",
    "                {'author': entry['Author']} for entry in dataset\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chroma_internet_client.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = ['2013', '2014', '2015', '2016-2017', '2018', '2019', '2020-1', '2020-2']  \n",
    "\n",
    "create_chroma_collections(years=years)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## access 2013 collection\n",
    "collection_2013 = chroma_internet_client.get_collection('2013pubmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-MiniLM-L6-cos-v1\", normalize_embeddings=True)\n",
    "\n",
    "# User's question\n",
    "user_question = 'CASK Disorder'\n",
    "\n",
    "# Embed the user's question\n",
    "user_question_embedding = sentence_transformer_ef([user_question])[0]\n",
    "\n",
    "search_results = collection_2013.query(query_embeddings=[user_question_embedding], n_results=5)\n",
    "print(user_question)\n",
    "# Print the search results\n",
    "for i, result in enumerate(search_results['ids'][0]):\n",
    "    document_id = result\n",
    "    metadata = search_results['metadatas'][0][i]  # Access the corresponding metadata\n",
    "    similarity_score = search_results['distances'][0][i]  # Access the corresponding similarity score\n",
    "    document = search_results['documents'][0][i]  # Access the corresponding document\n",
    "\n",
    "    print(f\"PMID: {document_id}\")\n",
    "    # print(f\"Title: {metadata['title']}\")\n",
    "    print(f\"Author: {metadata['author']}\")\n",
    "    print(document)\n",
    "    print(f\"Similarity Score: {similarity_score}\")\n",
    "    print(\"---------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_internet_client.list_collections()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

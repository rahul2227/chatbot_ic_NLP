{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-pBdK3CEzC13",
    "outputId": "6187c1a3-ec5a-44e9-c1ec-5979bcfb7755"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1620\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# Specify the path to your JSON file\n",
    "json_file_path = '/Users/vasu/Desktop/project/chatbot_ic_NLP/lib/NLP-Models/2013pubmed.json'\n",
    "\n",
    "# Open the JSON file and load the data\n",
    "with open(json_file_path, 'r') as json_file:\n",
    "    dataset = json.load(json_file)\n",
    "\n",
    "# Print the loaded dataset\n",
    "print(len(dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "68kJcpXFzLd_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -Uq chromadb numpy datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence_transformers in /Users/vasu/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (4.32.1)\n",
      "Requirement already satisfied: tqdm in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.26.3)\n",
      "Requirement already satisfied: scikit-learn in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.3.0)\n",
      "Requirement already satisfied: scipy in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: nltk in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sentence_transformers) (0.20.2)\n",
      "Requirement already satisfied: filelock in /Users/vasu/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (3.9.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2023.10.0)\n",
      "Requirement already satisfied: requests in /Users/vasu/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (6.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (4.9.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence_transformers) (23.1)\n",
      "Requirement already satisfied: sympy in /Users/vasu/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (1.11.1)\n",
      "Requirement already satisfied: networkx in /Users/vasu/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1)\n",
      "Requirement already satisfied: jinja2 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from torch>=1.6.0->sentence_transformers) (3.1.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (2022.7.9)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.13.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence_transformers) (0.3.2)\n",
      "Requirement already satisfied: click in /Users/vasu/anaconda3/lib/python3.11/site-packages (from nltk->sentence_transformers) (8.0.4)\n",
      "Requirement already satisfied: joblib in /Users/vasu/anaconda3/lib/python3.11/site-packages (from nltk->sentence_transformers) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from scikit-learn->sentence_transformers) (2.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from torchvision->sentence_transformers) (9.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence_transformers) (2.1.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (1.26.16)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence_transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence_transformers) (1.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8hgCDdigzRKd"
   },
   "outputs": [],
   "source": [
    "# Import Chroma and instantiate a client. The default Chroma client is ephemeral, meaning it will not save to disk.\n",
    "import chromadb\n",
    "\n",
    "from chromadb import EmbeddingFunction\n",
    "\n",
    "\n",
    "client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "QhLBGdCQzYDU"
   },
   "outputs": [],
   "source": [
    "from chromadb.utils import embedding_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "8WfAb7CCze1u"
   },
   "outputs": [],
   "source": [
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"multi-qa-MiniLM-L6-cos-v1\")\n",
    "my_collection = client.create_collection(\"2013pubmed\", embedding_function=sentence_transformer_ef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68GhD0RbzgnU"
   },
   "outputs": [],
   "source": [
    "# Extract data from the dataset and store it in the collection\n",
    "my_collection.add(\n",
    "    ids=[str(entry['PMID']) for entry in dataset],\n",
    "    documents=[entry['Abstract'] for entry in dataset],\n",
    "    metadatas=[\n",
    "        {'title': entry['Title'], 'author': entry['Author']} for entry in dataset\n",
    "    ],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose a specific document (e.g., using its PMID)\n",
    "pmid_to_inspect = '25529585'\n",
    "\n",
    "retrieved_data = my_collection.get(ids=[pmid_to_inspect])\n",
    "\n",
    "# Print the retrieved data\n",
    "print(retrieved_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(my_collection.get(ids=['21723361'], include= ['documents', 'embeddings']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "# User's question\n",
    "user_question = 'CASK Disorders'\n",
    "\n",
    "# Embed the user's question\n",
    "user_question_embedding = sentence_transformer_ef([user_question])[0]\n",
    "\n",
    "search_results = my_collection.query(query_embeddings=[user_question_embedding], n_results=5)\n",
    "print(user_question)\n",
    "# Print the search results\n",
    "for i, result in enumerate(search_results['ids'][0]):\n",
    "    document_id = result\n",
    "    metadata = search_results['metadatas'][0][i]  # Access the corresponding metadata\n",
    "    similarity_score = search_results['distances'][0][i]  # Access the corresponding similarity score\n",
    "    document = search_results['documents'][0][i]  # Access the corresponding document\n",
    "\n",
    "    print(f\"PMID: {document_id}\")\n",
    "    print(f\"Title: {metadata['title']}\")\n",
    "    print(f\"Author: {metadata['author']}\")\n",
    "    print(document)\n",
    "    print(f\"Similarity Score: {similarity_score}\")\n",
    "    print(\"---------------\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Requirement already satisfied: flask in /Users/vasu/anaconda3/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: Werkzeug>=2.2.2 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from flask) (2.2.3)\n",
      "Requirement already satisfied: Jinja2>=3.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from flask) (3.1.2)\n",
      "Requirement already satisfied: itsdangerous>=2.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from flask) (2.0.1)\n",
      "Requirement already satisfied: click>=8.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from flask) (8.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/vasu/anaconda3/lib/python3.11/site-packages (from Jinja2>=3.0->flask) (2.1.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install flask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# from flask import Flask, render_template, request\n",
    "# from chromadb.utils import embedding_functions\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "# import chromadb\n",
    "\n",
    "# app = Flask(__name__)\n",
    "\n",
    "\n",
    "\n",
    "# # Function to get search results for a user question\n",
    "# def get_search_results(user_question):\n",
    "#     user_question_embedding = sentence_transformer_ef([user_question])[0]\n",
    "#     search_results = my_collection.query(query_embeddings=[user_question_embedding], n_results=5)\n",
    "#     return search_results\n",
    "\n",
    "# @app.route('/', methods=['GET', 'POST'])\n",
    "# def index():\n",
    "#     if request.method == 'POST':\n",
    "#         user_question = request.form['query']\n",
    "#         if user_question:\n",
    "#             search_results = get_search_results(user_question)\n",
    "#             return render_template('index.html', query=user_question, results=search_results)\n",
    "\n",
    "#     return render_template('index.html', query=None, results=None)\n",
    "\n",
    "# if __name__ == '__main__':\n",
    "#     app.run(debug=True, port=8080)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}

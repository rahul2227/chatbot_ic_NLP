{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from openai import AsyncOpenAI\n",
    "import os\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_openai import OpenAI\n",
    "from getpass import getpass\n",
    "import json\n",
    "import traceback\n",
    "import time\n",
    "import asyncio\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter your OpenAI API key:\n"
     ]
    }
   ],
   "source": [
    "# Check if OPENAI_API_KEY environment variable is set\n",
    "if \"OPENAI_API_KEY\" not in os.environ:\n",
    "    print(\"Enter your OpenAI API key:\")\n",
    "    os.environ[\"OPENAI_API_KEY\"] = getpass()\n",
    "\n",
    "# evaluator setup\n",
    "# openai.api_key = os.environ.get(\"OPENAI_API_KEY\")\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")\n",
    "# openai.api_base = os.environ.get(\"OPENAI_API_BASE\")\n",
    "evaluator_model = \"gpt-4-1106-preview\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm = OpenAI(api_key=OPENAI_API_KEY)\n",
    "llm = AsyncOpenAI(api_key=OPENAI_API_KEY)\n",
    "# llm = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How would the body react if prescribed medication was suddenly discontinued?\n"
     ]
    }
   ],
   "source": [
    "# get question\n",
    "question_ind = np.random.choice(60)\n",
    "question_data = json.load(open(\"G:/All Flutter Applications/NLP with transformers project/chatbot_ic/lib/backend/evaluations/evaluation_ques.json\", \"r\"))[question_ind]\n",
    "question = question_data[\"question\"]\n",
    "print(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ## Prompt \n",
    "# QUERY_PROMPT_MODEL_PT = PromptTemplate(\n",
    "#     input_variables=[\"question\", \"context\"],\n",
    "#     template = \"\"\"You are an AI language model assistant. Your task is to generate answer\n",
    "#     by taking information from the relevant context provided from a vector \n",
    "#     database. By considering multiple perspectives on the user question, your goal is to help\n",
    "#     the user understand the concept of the question asked that is also relevant to the context provided. \n",
    "#     Provide these answers with proper type setting.\n",
    "\n",
    "#     Original question: {question}\n",
    "#     Context : {context}\n",
    "#     \"\"\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import warnings\n",
    "\n",
    "# Suppress TypedStorage deprecation warning\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"TypedStorage is deprecated.*\")\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, message=\"LangChainDeprecationWarning: The function `run` was deprecated.*\")\n",
    "\n",
    "\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "\n",
    "import json\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "from chromadb import EmbeddingFunction\n",
    "from chromadb.utils import embedding_functions\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain_openai import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_context_with_max_similarity(user_question):\n",
    "    # Initialize SentenceTransformer model\n",
    "    sentence_transformer_ef = embedding_functions.SentenceTransformerEmbeddingFunction(model_name=\"all-MiniLM-L12-v2\", normalize_embeddings=True)\n",
    "\n",
    "    # Embed the user's question\n",
    "    user_question_embedding = sentence_transformer_ef([user_question])[0]\n",
    "\n",
    "    # Perform the query using Chroma\n",
    "    search_results = collection_2013.query(query_embeddings=[user_question_embedding], n_results=5)\n",
    "\n",
    "    # Find the index of the context with the maximum similarity score\n",
    "    max_similarity_index = search_results['distances'][0].index(max(search_results['distances'][0]))\n",
    "\n",
    "    # Get the context with the maximum similarity score\n",
    "    context_with_max_similarity = search_results['documents'][0][max_similarity_index]\n",
    "\n",
    "    return context_with_max_similarity\n",
    "\n",
    "chroma_internet_client = chromadb.HttpClient(host='16.171.68.145', port=8000, settings=Settings(allow_reset=True))\n",
    "\n",
    "collection_2013 = chroma_internet_client.get_collection('2013pubmed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "QUERY_PROMPT_MODEL = f\"\"\"\n",
    "You are an AI language model assistant. Your task is to generate answer\n",
    "    by taking information from the relevant context provided from a vector \n",
    "    database. By considering multiple perspectives on the user question, your goal is to help\n",
    "    the user understand the concept of the question asked that is also relevant to the context provided. \n",
    "    Provide these answers with proper type setting.\n",
    "\n",
    "    Original question: {question}\n",
    "    Context : {context}\n",
    "\"\"\"\n",
    "#{context}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consistently inadequate sleep can have various potential long-term effects on both physical and mental health. Some of the consequences include:\n",
      "\n",
      "1. **Cognitive Impairment:** Chronic sleep deprivation can impair cognitive function, leading to difficulties in concentration, memory, and decision-making.\n",
      "\n",
      "2. **Mood disorders:** Lack of sleep is closely linked to mood disorders such as depression and anxiety. Prolonged sleep deprivation can exacerbate these conditions.\n",
      "\n",
      "3. **Weakened immune system:** Inadequate sleep weakens the immune system, making individuals more susceptible to infections and illnesses.\n",
      "\n",
      "4. **Weight gain and obesity:** Sleep deprivation can disrupt hormones that regulate appetite, leading to increased food cravings and weight gain over time.\n",
      "\n",
      "5. **Increased risk of chronic diseases:** Long-term inadequate sleep has been associated with a higher risk of developing chronic conditions such as diabetes, heart disease, and hypertension.\n",
      "\n",
      "6. **Impaired physical performance:** Lack of adequate rest can impair physical performance, coordination, and reaction times, increasing the risk of accidents and injuries.\n",
      "\n",
      "It is essential to prioritize sleep and establish healthy sleep habits to prevent these long-term effects and maintain overall well-being.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    try:\n",
    "        chat_completion = await llm.chat.completions.create(\n",
    "            model=\"gpt-3.5-turbo\",\n",
    "            messages=[{\"role\": \"user\", \"content\": QUERY_PROMPT_MODEL}],\n",
    "            stream=False,\n",
    "        )\n",
    "        if isinstance(chat_completion, tuple):\n",
    "            # Handle tuple response\n",
    "            print(\"Received tuple response:\", chat_completion)\n",
    "            # Optionally, retry or handle the tuple response as needed\n",
    "            continue\n",
    "\n",
    "        if isinstance(chat_completion, dict):\n",
    "            # Not stream\n",
    "            answer = chat_completion.choices[0].message.content\n",
    "        else:\n",
    "            # Stream\n",
    "            # for token in chat_completion:\n",
    "            #     print(type(token))\n",
    "            #     print(token)\n",
    "            #     print(i)\n",
    "            # Access the answer outside the loop\n",
    "            answer = chat_completion.choices[0].message.content\n",
    "        break\n",
    "    except Exception as exc:\n",
    "        print(traceback.format_exc())\n",
    "        print(exc)\n",
    "        if i != 9:\n",
    "            print(f\"Retrying... (i = {i})\")\n",
    "            time.sleep(3)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_prompt = f\"\"\"\n",
    "        Your task is to evaluate a student's response to a given exercise. In the exercise, the student is provided with some general context consisting of 3 titles and abstracts of medical articles.\n",
    "        The student is furthermore asked a question, which he should answer correctly making use of the provided context.\n",
    "        The exercise tests the student's abilities regarding grammar, reading comprehension and logical reasoning. The student's answer starts after the *** symbol.\n",
    "        Please provide your general assessment about the answer provided by the student (the part after the *** symbol).\n",
    "        Is it correct? Is it grammatically correct? Is it consistent with the given context?\n",
    "        Furthermore, grade the student’s answer in terms of grammar, coherence, consistency with the context and whether it is correct or not. Moreover, please provide your best guess of what the academic degree of the student might be, as reflected from the answer. Choose from possible 4 possible categories: A: no degree. B: bachelor's degree. C: master's degree. D: doctoral degree. Use the following grade format: Grammar: #/10, Coherence: #/10, Context: #/10, Correctness: #/10, where the \"#\" should be replaces by a number between 0 (worst) and 10 (best).\n",
    "        Context: {context}\n",
    "        Question: {question}\n",
    "        Answer: *** {answer}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It seems there's no context provided in your message. However, I can provide general information about the potential long-term effects of consistently inadequate sleep based on existing scientific knowledge. \n",
      "\n",
      "**Potential Long-Term Effects of Inadequate Sleep:**\n",
      "\n",
      "1. **Cognitive Impairment**: Chronic sleep deprivation can lead to difficulties in concentration, memory, and cognitive processing. This impairment can affect job performance, academic learning, and daily activities.\n",
      "\n",
      "2. **Mood Disorders**: Inadequate sleep has been linked to mental health issues such as depression, anxiety, and irritability. Over time, lack of sleep can aggravate these symptoms and potentially lead to more severe mental illnesses.\n",
      "\n",
      "3. **Cardiovascular Health Risks**: Long-term sleep deprivation has been associated with increased risk of heart disease, hypertension, stroke, and coronary artery disease due to increased stress hormone levels and blood pressure.\n",
      "\n",
      "4. **Weight Gain and Obesity**: Poor sleep patterns can disrupt appetite-regulating hormones, leading to increased hunger and calorie consumption, which in turn can contribute to obesity.\n",
      "\n",
      "5. **Immune Function**: Sustained lack of sleep can weaken the immune system, making the body more susceptible to infections.\n",
      "\n",
      "6. **Endocrine and Metabolic Issues**: Chronic sleep loss can affect the body’s ability to regulate glucose and could potentially lead to insulin resistance and Type 2 diabetes.\n",
      "\n",
      "7. **Hormonal Imbalance**: Sleep affects the release of certain hormones, including those responsible for growth and stress. Prolonged sleep disruption can lead to hormonal imbalances.\n",
      "\n",
      "8. **Decreased Fertility**: Inadequate sleep can also impact reproductive hormones, potentially affecting fertility in both men and women.\n",
      "\n",
      "9. **Risk of Accidents**: Drowsiness increases the risk of accidents and injuries, particularly in jobs that require attention and precision.\n",
      "\n",
      "10. **Reduced Quality of Life**: Overall wellbeing and life satisfaction can be decreased due to the impact of chronic sleep deprivation on physical and mental health.\n",
      "\n",
      "To fully understand the effects of inadequate sleep on an individual, it would be imperative to have more specific context, such as the person's age, lifestyle, medical history, and the nature of their sleep deprivation (such as whether it's due to a sleep disorder, work schedule, stress, etc.). An in-depth analysis tailored to the individual would likely consider these factors.\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    try:\n",
    "        chat_completion = await llm.chat.completions.create(\n",
    "            model=evaluator_model,\n",
    "            messages=[{\"role\": \"user\", \"content\": QUERY_PROMPT_MODEL}],\n",
    "            stream=False,\n",
    "        )\n",
    "        if isinstance(chat_completion, tuple):\n",
    "            # Handle tuple response\n",
    "            print(\"Received tuple response:\", chat_completion)\n",
    "            # Optionally, retry or handle the tuple response as needed\n",
    "            continue\n",
    "\n",
    "        if isinstance(chat_completion, dict):\n",
    "            # Not stream\n",
    "            answer = chat_completion.choices[0].message.content\n",
    "        else:\n",
    "            # Stream\n",
    "            # for token in chat_completion:\n",
    "            #     print(type(token))\n",
    "            #     print(token)\n",
    "            #     print(i)\n",
    "            # Access the answer outside the loop\n",
    "            answer = chat_completion.choices[0].message.content\n",
    "        break\n",
    "    except Exception as exc:\n",
    "        print(traceback.format_exc())\n",
    "        print(exc)\n",
    "        if i != 9:\n",
    "            print(f\"Retrying... (i = {i})\")\n",
    "            time.sleep(3)\n",
    "\n",
    "print(answer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_chain = LLMChain(prompt=QUERY_PROMPT, llm=llm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Chroma db query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
